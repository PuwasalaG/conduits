---
output: github_document
---

<!-- README.md is generated from README.Rmd. Please edit that file -->

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "man/figures/README-",
  out.width = "100%",
  eval = TRUE
)
```


# conduits (CONDitional UI for Time Series normalisation)
 <img src="man/figures/logo.png" align="right" height="190"/>
<!-- badges: start -->
<!-- badges: end -->

Package `conduits` provides an user interface for conditionally normalising a time series. This also facilitates functions to produce conditional cross-correlations between two normalised time series at different lags while providing some graphical tools for visualisation. 

`conduits` can also be used to estimate the time delay between two sensor locations in river systems.  

## Installation

You can install `conduits` from github with:

``` r
# install.packages("devtools")
devtools::install_github("PuwasalaG/conduits")
```
## Example

This is a basic example which shows you how to use functions in `conduits`:

`conduits` contains a set of water-quality variables measured by in-situ sensors from the Pringle Creek located in Wise County, Texas. This is one of the aquatic NEON field sites hosted by the US Forest Service. 

This data contains water-quality variables such as, turbidity, specific conductance, dissolved oxygen, pH and fDOM along with surface elevation and surface temperature from two sites located about 200m apart. Data are available from $2019-07-01$ to $2019-12-31$ at every 5 mintues. 

In this example we choose turbidity from upstream and downstream sites to calculate the cross-correlation while conditioning on level, temperature and conductance from the upstream location.  

Let us first prepare data as follows

```{r prepare_data}
library(conduits)
library(tidyverse)
```

# Data

`conduits` contains `NEON_PRIN_5min_cleaned`, a set of water-quality variables measured by in-situ sensors from Pringle Creek located in Wise County, Texas. This is one of the aquatic NEON field sites hosted by the US Forest Service. 

This data contains water-quality variables such as turbidity, specific conductance, dissolved oxygen, pH and fDOM along with surface elevation and surface temperature from two sites located about 200m apart. Data are available from $2019-07-01$ to $2019-12-31$ at every 5 minutes. 

In this example, we choose turbidity from upstream and downstream sites to calculate the cross-correlation while conditioning on the water level, temperature and conductance from the upstream location.

Let us first prepare data as follows


```{r}
data <- NEON_PRIN_5min_cleaned %>%
  dplyr::filter(site == "upstream") %>%
  dplyr::select(Timestamp, turbidity, level,
                conductance, temperature) %>%
  tsibble::as_tsibble(index = Timestamp)
head(data)
```


### Conditional normalisation

The following code shows how to use the `conditional_moments` function to normalise turbidity from upstream sites.

```{r conditional_moments}
# Estimating conditional mean of the turbidity from the upstream site 

fit_mean <- data %>%
  conditional_mean(
    turbidity ~ s(level, k = 8) + s(conductance, k = 8) + s(temperature, k = 8))

summary(fit_mean)
class(fit_mean)

# Estimating conditional variance of the turbidity from the upstream site 

fit_var <- data %>%
  conditional_var(
    turbidity ~ s(level, k = 7) + s(conductance, k = 7) + s(temperature, k = 7),
    family = "Gamma",
    fit_mean
  )

class(fit_var)
summary(fit_var)

# Normalize the series using conditional moments
new_ts <- data %>%
  dplyr::mutate(
    ystar = normalize(., turbidity, fit_mean, fit_var))

```





