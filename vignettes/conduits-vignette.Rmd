---
title: "CONDitional UI for Time Series normalisation"
author: "Puwasala Gamakumara<hr>"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{my-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---


```{r setup, include = FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  collapse = TRUE,
  comment = "#>",
  fig.height = 5,
  fig.width = 8,
  fig.align = "center",
  cache = TRUE
)

library(conduits)
library(lubridate)
library(tidyverse)
library(mgvc)
library(forecast)

```

# Introduction

Package `conduits` provides an user interface for conditionally normalising a time series. This also facilitates functions to produce conditional cross-correlations between two normalised time series at different lags while providing some graphical tools for visualisation. 

`conduits` can also be used to estimate the time delay between two sensor locations in river systems.  

Using water-quality variables measured by in-situ sensors from the Pringle Creek located in Wise County, Texas, we demonstrate how each function in this package works.

# Data

`conduits` contains a set of water-quality variables measured by in-situ sensors from the Pringle Creek located in Wise County, Texas. This is one of the aquatic NEON field sites hosted by the US Forest Service. 

This data contains water-quality variables such as, turbidity, specific conductance, dissolved oxygen, pH and fDOM along with surface elevation and surface temperature from two sites located about 200m apart. Data are available from $2019-07-01$ to $2019-12-31$ at every 5 mintues. 

In this example we choose turbidity from upstream and downstream sites to calculate the cross-correlation while conditioning on level, temperature and conductance from the upstream location.  

Let us first prepare data as follows

```{r prepare_data}

data_z <- NEON_PRIN_5min_cleaned %>% 
  filter(Timestamp >= ymd("2019-10-01") 
         & Timestamp < ymd("2020-01-01"),
         site == "upstream") %>%
  select(Timestamp, level, conductance, temperature) %>% 
  rename("level_up" = level,
         "conductance_up" = conductance,
         "temperature_up" = temperature)

data_xy <- NEON_PRIN_5min_cleaned %>% 
  filter(Timestamp >= ymd("2019-10-01") 
         & Timestamp < ymd("2020-01-01")) %>% 
  select(Timestamp, site, turbidity) %>% 
  tidyr::spread(key = site, value = turbidity) %>% 
  rename("turbidity_up" = upstream,
         "turbidity_down" = downstream) %>% 
  mutate(turbidity_up = if_else(turbidity_up == 0,
                                      as.numeric(NA),
                                      turbidity_up))

data_normalisation <- data_xy %>% 
  left_join(data_z, by = "Timestamp")

head(data_normalisation)
```



# Conditional normalisation

Let $y_t$ is a variable observed at times $t = 1,...,T$ and $\mathbf{z}_t = (z_{1,t},...,z_{p,t})$ be a $p$ dimensional vector of variables measured at the same time points. Assuming the expectation and the variance of $y_t$ are functions of $\mathbf{z}_t$, i.e., $\text{E}(y_t|\mathbf{z}_t) = m(\mathbf{z}_t)$ and $\text{V}(y_t|\mathbf{z}_t) = v(\mathbf{z}_t)$, we normalise $y_t$ conditional on $\mathbf{z}_t$ as, 

$$
y_t^* = \frac{y_t - \hat{m}(\mathbf{z}_t)}{\sqrt{\hat{v}(\mathbf{z}_t)}}
$$
To estimate $m(\mathbf{z}_t)$ we fit Generalised Additive Models (GAMs) to $y_t$ using $\mathbf{z}_t$ as predictors. 
i.e., we fit the following model.

$$
y_t = \alpha_0 + \sum_{i=1}^pf_i(z_{i,t}) + \varepsilon_{t}
$$
where, $f_i(.)$ are smooth functions and $\varepsilon_{1}, \varepsilon_{2},...,\varepsilon_{t}$ have mean $0$ and variance $v(\mathbf{z}_t)$. This gives, 

$$
\hat{m}(\mathbf{z}_t) = \hat{\alpha}_0 + \sum_{i=1}^p\hat{f}_i(z_{i,t}).
$$

Next, to estimate $v(\mathbf{z}_t)$, we fit GAMs to the squared errors from the previous conditional mean model, i.e., $[y_t - \hat{m}(\mathbf{z}_t)]^2$ using $\mathbf{z}_t$ as predictors. i.e., we fit the following model.

\begin{align*}
[y_t- \hat{m}(\mathbf{z}_t)]^2 & \sim \text{Gamma}(v(\mathbf{z}_t), r),\\
  \log(v(\mathbf{z}_t)) &= \beta_0 + \sum_{i=1}^p g_{i}(z_{i,t}),
\end{align*}

where, $g_i(.)$ are smooth functions. This gives,

$$
\hat{v}(\mathbf{z}_t) = \text{exp}\bigg(\hat{\beta}_0 + \sum_{i=1}^p \hat{g}_{i}(z_{i,t})\bigg)
$$

We use `gam` function from `mgcv` package to fit the GAMs in above conditional mean and variance models.  


## Conditionally normalising turbidity from upstream sensor in Pringle Creek

We have implemented the conditional normalising methods in `conditional_moments` function. Let us now see how to use `conditional_moments` function to normalise turbidity from the upstream site in the Pringle Creek. We use water level, temperature and conductance measured at the same upstream site as predictors. Therefore the normalisation is done conditional to these predictors. 

```{r conditional_moments}

cond_moments_x <- data_normalisation %>% 
  conditional_moments(x = turbidity_up,
                      z_numeric = c(level_up, temperature_up,
                                    conductance_up),
                      knots_mean = c(8,8,8),
                      knots_variance = c(7,7,7))
head(cond_moments_x$data_conditional_moments)
```

To visualise the fitted models for conditional means and variances, we can use the `autoplot` method written for `conditional_moments` functions. The code is shown below. 


```{r vis_mean_models}

autoplot(cond_moments_x, type = "mean")
autoplot(cond_moments_x, type = "variance")
```

We now plot the conditionally normalised turbidity series. 

```{r vis_nomalised_turbidity}

normalised_x <- cond_moments_x$data_conditional_moments %>% 
  mutate(X_star = (turbidity_up - E_turbidity_up)
         /sqrt(Var_turbidity_up)) %>% 
  select(Timestamp, X_star)

X_timeplot <- normalised_x %>% 
  ggplot(aes(Timestamp, X_star)) + 
  geom_line() +
  ylab("Turbidity upstream (FNU)")

X_hist <- normalised_x %>% 
  ggplot(aes(X_star)) + 
  geom_histogram() +
  xlab("Turbidity upstream (FNU)") +
  ylab("Count")

plot_normalised_turb_up <- gridExtra::grid.arrange(grobs = list(X_timeplot, X_hist))

```

# Conditional cross-correlation function

The conditionally normalised series can be used to compute conditional cross-correlation function between two time series at lag $k$. Suppose we have another time series $x_t$ measured at the same times as $y_t$.
Then we define the cross-correlation between $x_t$ and $y_{t+k}$ conditional on $\mathbf{z}_t$ as, 

$$
c_k(\mathbf{z}_t) = \text{E}[x_t^*y_{t+k}^*|\mathbf{z}_t]
$$
for $k=1,...K$. 

Using GAMs we can fit the following models to estimate $c_k(\mathbf{z}_t)$. 

\begin{align*}
x_t^*y_{t+k}^* \sim N(c_k(\mathbf{z}_t), u_k^2),
\end{align*}
\begin{align*}
\eta(c_k(\mathbf{z}_t)) = \phi_0 + \sum_{i=1}^p s_i(z_{i,t}).
\end{align*}

where, $s_i(.)$ are smooth functions and $\eta(.)$ is a monotonic link function which is given by,
\begin{align*}
\eta^{-1}(u) = \frac{e^u - 1}{e^u + 1}.
\end{align*}

We have implemented these methods in `conditional_ccf` function and GAMs are fitted using natural splines in `splines` package. 

## Conditional cross-correlation between turbidity measured at upstream and downstream sensors in Pringle Creek

Let us see how to use `conditional_ccf` function to compute conditional cross-correlations between turbidity measured at upstream and downstream sensors in Pringle Creek. Let $x_t$ be the turbidity measured at upstream sensor and $y_t$ be the turbidity measured at downstream sensor. Further, let $\mathbf{z}_t$ be water level, temperature and conductance measured at upstream sensor. The conditional cross-correlations are computed at lags $k=1,...,24$. 

```{r ccf}

cond_ccf <- data_normalisation %>%
  conduits::conditional_ccf(x = turbidity_up,
                            y = turbidity_down,
                            z_numeric = c(level_up, 
                                          temperature_up,
                                          conductance_up),
                            k = 1:24,
                            knots_mean = list(x = c(8,8,8), 
                                              y = c(8,8,8)),
                            knots_variance = list(x = c(7,7,7), 
                                                  y = c(7,7,7)),
                            df_correlation = c(4,2,4))

```

We can use the `autoplot` method written for `conditional_ccf` to visualise the fitted models as follows. 

```{r vis_ccf}

autoplot(cond_ccf, type = "cross-correlation", k=c(1,10,24))

```

# Estimating lag time between two locations in a river using conditional cross-correlations

River flow time or the lag time can be defined as the time that water takes to flow downstream from an upstream river location. This time can be varied due to the upstream river behaviour. For example, when the upstream water level is increases, water flow will typically be increased and hence the lag time will decline. On the other hand, when the water level is low, water will likely to be flowing more slowly and hence the lag time will increase. Therefore it is important to consider the conditional river behaviour when estimating lag time between two river locations. 

We can define the lag time $d_t$ using the conditional cross-correlations as the lag that gives maximum conditional cross-correlation. i.e., 

$$
\hat{d}_t = \underset{k}{\operatorname{argmax}}\quad \hat{c}_{k}(\mathbf{z}_t).
$$

The function `estimate_dt` can be used to compute the lag time between two river locations as follows. 

```{r estimate_dt}

Estimate_dt <- cond_ccf %>% 
  estimate_dt(new_data = data_normalisation, k_min = 1, k_max = 24)

head(Estimate_dt$data_dt)
```

We can also visualise the estimated $d_t$ with each predictor used in the conditional cross-correlation models. For that we can use `autoplot` method written for `estimate_dt` function as follows. Setting `interval = TRUE` will compute prediction intervals which were obtained using Sieve bootstrap method which will take more computational time. 

```{r vis_dt}

# set interval=TRUE to compute prediction intervals (This will take more computational time)
autoplot(object = Estimate_dt, interval = FALSE)
```

# Modeling downstream turbidity with upstream water-quality variables

Suppose we are interested to model turbidity at downstream sensor using water-quality variables at upstream sensor. For that, it is important to compute the upstream water-qaulity variables with the time lag. This will account for the time the water takes to flow downstream from the upstream location. We can therefore use the lag times estimated in the previous section. The function `map_lags` can be used to compute the lagged variables of upstream sensor using the estimated time lags as follows. 

```{r compute_lagged_variables}

# We will first select the estimated dt corresponds to each time stamp

estim_dt <- Estimate_dt$data_dt %>% 
  select(Timestamp, dt)

data_lagged_upstream <- data_normalisation %>% 
  left_join(estim_dt, by = "Timestamp")

data_lagged_upstream <- data_lagged_upstream %>% 
  map_lags(up = c(turbidity_up, level_up, 
                  conductance_up, temperature_up), 
           down = c(turbidity_down),
           lag = dt)

head(data_lagged_upstream)
```

## Visualising the relationship between variables

```{r vis_data}

data_lagged_upstream %>% 
  select(-Timestamp, -max_lag) %>% 
  GGally::ggpairs()

```

We can fit the following GAM to the Turbidity downstream using upstream variables as follows

```{r fit_gam_turbidity}

# computing log of turbidity

data_modeling <- data_lagged_upstream %>% 
  mutate(turbidity_down_log = log(turbidity_down),
         turbidity_up_dt_log = log(turbidity_up_dt)) %>% 
  select(Timestamp, turbidity_down_log, turbidity_up_dt_log,
         level_up_dt, conductance_up_dt, temperature_up_dt) %>% 
  drop_na()
  

fit_gam_turb <- mgcv::gam(turbidity_down_log ~ 
                            s(turbidity_up_dt_log) +
                            s(conductance_up_dt) +
                            s(level_up_dt) +
                            s(temperature_up_dt),
                          data = data_modeling)

summary(fit_gam_turb)
```
```{r vis_gam_fit}
visreg::visreg(fit_gam_turb, plot = FALSE) %>% 
  purrr::map(function(x){plot(x, gg = TRUE) + theme_bw()}) %>% 
  gridExtra::marrangeGrob(ncol = 2, nrow = 3)
```


```{r residual_check_gam_fit}

forecast::ggtsdisplay(fit_gam_turb$residuals)

par(mfrow = c(2,2), mar = c(1,1,1,1))
mgcv::gam.check(fit_gam_turb)

```
The fitted model explains $79.2\%$ variation of the Turbidity at downstream sensor.

